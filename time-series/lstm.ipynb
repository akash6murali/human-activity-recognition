{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201547f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0bd65a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prepared data from: /Users/akashmurali/Documents/capstone/project/capture24/preprocessed\n",
      "\n",
      "Loaded data:\n",
      "  X shape: (934762, 1000, 3)\n",
      "  Y shape: (934762,)\n",
      "  Number of participants: 151\n"
     ]
    }
   ],
   "source": [
    "def load_prepared_data(data_dir='/Users/akashmurali/Documents/capstone/project/capture24/preprocessed', schema='WillettsSpecific2018'):\n",
    "    print(f\"Loading prepared data from: {data_dir}\")\n",
    "    \n",
    "    X = np.load(os.path.join(data_dir, 'X.npy'))\n",
    "    Y = np.load(os.path.join(data_dir, f'Y_{schema}.npy'), allow_pickle=True)\n",
    "    T = np.load(os.path.join(data_dir, 'T.npy'), allow_pickle=True)\n",
    "    P = np.load(os.path.join(data_dir, 'P.npy'), allow_pickle=True)\n",
    "    \n",
    "    print(f\"\\nLoaded data:\")\n",
    "    print(f\"  X shape: {X.shape}\")\n",
    "    print(f\"  Y shape: {Y.shape}\")\n",
    "    print(f\"  Number of participants: {len(np.unique(P))}\")\n",
    "    \n",
    "    return X, Y, T, P\n",
    "\n",
    "\n",
    "# Usage\n",
    "X, Y, T, P = load_prepared_data(schema='WillettsSpecific2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf3620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "\n",
      "Data split:\n",
      "  Train: 63,445 windows from 10 participants\n",
      "  Test: 61,592 windows from 10 participants\n",
      "\n",
      "Model: 69,386 parameters\n",
      "\n",
      "======================================================================\n",
      "Training LSTM\n",
      "======================================================================\n",
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:17<00:00,  2.50it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:45<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.4716, Acc=47.13%\n",
      "Val: Loss=1.5263, Acc=39.88%, F1=0.0831\n",
      "✓ Saved best model\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:09<00:00,  2.57it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:43<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.4170, Acc=49.64%\n",
      "Val: Loss=1.4552, Acc=44.98%, F1=0.1118\n",
      "✓ Saved best model\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:15<00:00,  2.52it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:39<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.3726, Acc=51.50%\n",
      "Val: Loss=1.3533, Acc=52.49%, F1=0.1255\n",
      "✓ Saved best model\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:09<00:00,  2.56it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:37<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.3558, Acc=52.21%\n",
      "Val: Loss=1.3158, Acc=53.07%, F1=0.1229\n",
      "✓ Saved best model\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:16<00:00,  2.51it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:36<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.3957, Acc=50.75%\n",
      "Val: Loss=1.5260, Acc=40.30%, F1=0.1254\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:18<00:00,  2.49it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:40<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.4201, Acc=49.96%\n",
      "Val: Loss=1.4059, Acc=51.07%, F1=0.1178\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:17<00:00,  2.50it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:37<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.3820, Acc=51.35%\n",
      "Val: Loss=1.3210, Acc=53.27%, F1=0.1236\n",
      "✓ Saved best model\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:22<00:00,  2.47it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:31<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.3538, Acc=52.20%\n",
      "Val: Loss=1.3434, Acc=52.93%, F1=0.1227\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:10<00:00,  2.56it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:37<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.3682, Acc=52.32%\n",
      "Val: Loss=1.3582, Acc=54.00%, F1=0.1471\n",
      "✓ Saved best model\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:11<00:00,  2.55it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:38<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.4102, Acc=50.33%\n",
      "Val: Loss=1.3854, Acc=51.87%, F1=0.1212\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:08<00:00,  2.57it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:41<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.3619, Acc=52.00%\n",
      "Val: Loss=1.3185, Acc=53.87%, F1=0.1303\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:16<00:00,  2.51it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:37<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.3575, Acc=52.42%\n",
      "Val: Loss=1.3523, Acc=54.92%, F1=0.1352\n",
      "✓ Saved best model\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:10<00:00,  2.55it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:36<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.3599, Acc=52.31%\n",
      "Val: Loss=1.3486, Acc=51.90%, F1=0.1203\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:10<00:00,  2.55it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:35<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.3345, Acc=51.90%\n",
      "Val: Loss=1.2497, Acc=56.62%, F1=0.1763\n",
      "✓ Saved best model\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:11<00:00,  2.55it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:42<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.2583, Acc=54.71%\n",
      "Val: Loss=1.2174, Acc=55.37%, F1=0.1871\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:14<00:00,  2.52it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:40<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.1995, Acc=56.75%\n",
      "Val: Loss=1.1307, Acc=58.55%, F1=0.2217\n",
      "✓ Saved best model\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:13<00:00,  2.53it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:40<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.1529, Acc=57.05%\n",
      "Val: Loss=1.1448, Acc=57.34%, F1=0.2193\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [05:16<00:00,  2.51it/s]\n",
      "Validation: 100%|██████████| 199/199 [00:38<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.0897, Acc=60.38%\n",
      "Val: Loss=1.0839, Acc=60.42%, F1=0.2435\n",
      "✓ Saved best model\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [07:21<00:00,  1.80it/s]\n",
      "Validation: 100%|██████████| 199/199 [01:08<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.0389, Acc=62.29%\n",
      "Val: Loss=0.9787, Acc=64.61%, F1=0.3104\n",
      "✓ Saved best model\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 794/794 [08:04<00:00,  1.64it/s]\n",
      "Validation: 100%|██████████| 199/199 [05:26<00:00,  1.64s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.9841, Acc=65.21%\n",
      "Val: Loss=0.9720, Acc=64.94%, F1=0.3541\n",
      "✓ Saved best model\n",
      "\n",
      "======================================================================\n",
      "Test Evaluation\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 963/963 [03:37<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "  Accuracy: 55.17%\n",
      "  F1-Score: 0.2371\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# Dataset class\n",
    "class ActivityDataset(Dataset):\n",
    "    def __init__(self, X, Y, label_encoder=None):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        \n",
    "        if label_encoder is None:\n",
    "            unique_labels = np.unique(Y)\n",
    "            self.label_encoder = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        else:\n",
    "            self.label_encoder = label_encoder\n",
    "        \n",
    "        self.Y = torch.LongTensor([self.label_encoder[label] for label in Y])\n",
    "        self.idx_to_label = {idx: label for label, idx in self.label_encoder.items()}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "\n",
    "# Simple 1-layer LSTM\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size=3, hidden_size=256, num_classes=10, dropout=0.3):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        \n",
    "        # Single LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0  # No dropout for single layer\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, 1000, 3)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        # Use last hidden state\n",
    "        out = self.dropout(h_n[-1])  # (batch, hidden_size)\n",
    "        out = self.fc(out)  # (batch, num_classes)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(train_loader), 100 * correct / total\n",
    "\n",
    "\n",
    "# Validation function\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    return total_loss / len(val_loader), 100 * correct / total, f1\n",
    "\n",
    "\n",
    "# Main training function\n",
    "def train_lstm(X, Y, P, n_participants=100):\n",
    "    \"\"\"\n",
    "    Train LSTM on N participants\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # Filter for N participants\n",
    "    train_pids = [f'P{i:03d}' for i in range(1, n_participants + 1)]\n",
    "    test_pids = [f'P{i:03d}' for i in range(101, 150)]  # P101-P110 for testing\n",
    "    \n",
    "    train_mask = np.isin(P, train_pids)\n",
    "    test_mask = np.isin(P, test_pids)\n",
    "    \n",
    "    # Remove NaN labels\n",
    "    valid_train = train_mask & (Y != 'nan') & (~pd.isna(Y))\n",
    "    valid_test = test_mask & (Y != 'nan') & (~pd.isna(Y))\n",
    "    \n",
    "    X_train = X[valid_train]\n",
    "    Y_train = Y[valid_train]\n",
    "    X_test = X[valid_test]\n",
    "    Y_test = Y[valid_test]\n",
    "    \n",
    "    print(f\"\\nData split:\")\n",
    "    print(f\"  Train: {len(X_train):,} windows from {n_participants} participants\")\n",
    "    print(f\"  Test: {len(X_test):,} windows from 10 participants\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = ActivityDataset(X_train, Y_train)\n",
    "    test_dataset = ActivityDataset(X_test, Y_test, label_encoder=train_dataset.label_encoder)\n",
    "    \n",
    "    # Train/val split\n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        train_dataset, [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # Model\n",
    "    num_classes = len(train_dataset.dataset.label_encoder)\n",
    "    model = SimpleLSTM(input_size=3, hidden_size=256, num_classes=num_classes)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"\\nModel: {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "    \n",
    "    # Training setup\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0\n",
    "    epochs = 50\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Training LSTM\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc, val_f1 = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        print(f\"Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n",
    "        print(f\"Val: Loss={val_loss:.4f}, Acc={val_acc:.2f}%, F1={val_f1:.4f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), f'lstm_{n_participants}p.pth')\n",
    "            print(f\"✓ Saved best model\")\n",
    "    \n",
    "    # Final test\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Test Evaluation\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    model.load_state_dict(torch.load(f'lstm_{n_participants}p.pth'))\n",
    "    test_loss, test_acc, test_f1 = validate(model, test_loader, criterion, device)\n",
    "    \n",
    "    print(f\"\\nTest Results:\")\n",
    "    print(f\"  Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"  F1-Score: {test_f1:.4f}\")\n",
    "    \n",
    "    return model, test_acc, test_f1\n",
    "\n",
    "\n",
    "# Run training\n",
    "import pandas as pd\n",
    "\n",
    "model, test_acc, test_f1 = train_lstm(X, Y, P, n_participants=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e480f819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "har",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
